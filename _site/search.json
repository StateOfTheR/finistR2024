[
  {
    "objectID": "simulator.html",
    "href": "simulator.html",
    "title": "Setting up simulations in R",
    "section": "",
    "text": "simulator\nsimpr\nDeclareDesign\nMonteCarlo\nsimChef\nsimEngine"
  },
  {
    "objectID": "simulator.html#list-of-packages-for-data-simulation",
    "href": "simulator.html#list-of-packages-for-data-simulation",
    "title": "Setting up simulations in R",
    "section": "",
    "text": "simulator\nsimpr\nDeclareDesign\nMonteCarlo\nsimChef\nsimEngine"
  },
  {
    "objectID": "simulator.html#how-to-choose",
    "href": "simulator.html#how-to-choose",
    "title": "Setting up simulations in R",
    "section": "How to choose ?",
    "text": "How to choose ?\n\nNumber of dependencies\nNumber of reverse dependencies\nDate of latest commit\nDate of last release\nIs it on CRAN or only on Github?\nWho developed it?\nPhilosophy\n\n\n\n\nName\nVersion\n#deps\n#rev deps\nLatest commit\nLatest release\nDoc\nOn CRAN?\nDevelopers\n\n\n\n\nDeclareDesign\n1.0.10\n2\n1\n2024-04-13\n2024-04-21\n\nYes\nGraeme Blair\n\n\nMonteCarlo\n1.0.6\n6\n0\n2019-01-31\n2019-01-31\n\nYes\nChristian Hendrik Leschinski\n\n\nsimChef\n0.1.0\n22\n0\n2024-03-20\nNA\n\nNo\nTiffany Tang, James Duncan\n\n\nsimEngine\n1.4.0\n6\n0\n2024-04-13\n2024-04-04\n\nYes\nAvi Kenny, Charles Wolock\n\n\nsimpr\n0.2.6\n11\n0\n2024-07-16\n2023-04-26\n\nYes\nEthan Brown\n\n\nsimulator\n0.2.5\n1\n0\n2023-02-02\n2023-02-04\n\nYes\nJacob Bien"
  },
  {
    "objectID": "simulator.html#simpr",
    "href": "simulator.html#simpr",
    "title": "Setting up simulations in R",
    "section": "simpr",
    "text": "simpr\n\n\n\n\n\n\nProblem\n\n\n\n\nStudy: Pre-post comparison of the “Triglicious” intervention;\nResearch question: Did Triglicious improve students’ math scores?\nMethod: Paired t-test\n\n\n\n\nUsual base R solution\n\n## Set up parameters\nns &lt;- c(100L, 150L, 200L)\nmean_diffs &lt;- c(10, 20, 30)\nsds &lt;- c(50, 100)\nreps &lt;- 10L\n\n## Bring together into data frame\nresults_template &lt;- expand.grid(\n  n = ns, \n  mean_diff = mean_diffs, \n  sd = sds, \n  p.value = NA_real_\n)\nbase_r_sim &lt;- results_template[rep(1:nrow(results_template), each = reps), ]\n\n## Loop over rows of the data frame and calculate the p-value\nfor (i in 1:nrow(results_template)) {\n  params &lt;- base_r_sim[i,]\n  pre &lt;- rnorm(params$n, 0, params$sd)\n  post &lt;- pre + rnorm(params$n, params$mean_diff, params$sd)\n  base_r_sim$p.value[i] &lt;- t.test(pre, post)$p.value\n}\n\n## Display table output\nDT::datatable(base_r_sim)\n\n\n\n\n\nWhat is bad according to simpr authors:\n\nMost important pieces (data generating process, model specification, definitions, varying parameters) are hidden;\nWhat if there is an error?\nWhat about parallelization?\nIs this code sufficiently readable? Without the comments?\n\n\n\nSolution via simpr\n\n## Specify pre and post scores that differ by a given amount\nspecify(\n  pre  = ~ rnorm(n, 0, sd), \n  post = ~ pre + rnorm(n, mean_diff, sd)) |&gt; \n  ## Define parameters that can be varied\n  define(n = 100, mean_diff = 10, sd = 50) |&gt; \n  ## Generate datasets\n  generate(100) |&gt; \n  ## Fit datasets\n  fit(t = ~t.test(post, pre, paired = TRUE)) |&gt; \n  ## Collect results\n  tidy_fits() |&gt; \n  DT::datatable()\n\n\n\n\n\n\n\nA complete solution with varying parameters\n\nsim_vary &lt;- specify(\n  pre  = ~ rnorm(n, 0, sd),\n  post = ~ pre + rnorm(n, mean_diff, sd)\n) |&gt; \n  define(\n    n = c(100, 150, 200), \n    mean_diff = c(10, 20, 30), \n    sd = c(50, 100)\n  ) |&gt; \n  generate(100, .progress = TRUE) |&gt; \n  fit(t = ~t.test(post, pre, paired = TRUE)) |&gt; \n  tidy_fits()\n\nsim_vary |&gt; \n  dplyr::group_by(n, mean_diff, sd) |&gt; \n  dplyr::summarize(Power = mean(p.value &lt; 0.05)) |&gt; \n  ggplot(aes(n, Power)) + \n  geom_col() + \n  facet_grid(rows = vars(sd), cols = vars(mean_diff)) + \n  theme_bw()\n\n`summarise()` has grouped output by 'n', 'mean_diff'. You can override using\nthe `.groups` argument.\n\n\n\n\n\n\n\n\n\n\n\nPhilosophy\nThe simpr workflow, inspired by the infer package, distills a simulation study into five primary steps:\n\nspecify() your data-generating process;\ndefine() parameters that you want to systematically vary across your simulation design (e.g. n, effect size);\ngenerate() the simulation data;\nfit() models to your data (e.g. lm());\ntidy_fits() for consolidating results using broom::tidy(), such as computing power or Type I Error rates.\n\n\n\nReproducible workflows\n\nSame seed, same results;\nCan regenerate just a specific subset to see what happened in that particular dataset or fit;\nUseful in debugging and diagnosing unexpected results, etc.\n\n\nFiltering full simulation\n\nset.seed(500)\n\nspecify(a = ~ runif(6)) |&gt; \n  generate(3) |&gt; \n  dplyr::filter(.sim_id == 3)\n\nfull tibble\n--------------------------\n# A tibble: 1 × 3\n  .sim_id   rep sim             \n    &lt;int&gt; &lt;int&gt; &lt;list&gt;          \n1       3     3 &lt;tibble [6 × 1]&gt;\n\nsim[[1]]\n--------------------------\n# A tibble: 6 × 1\n      a\n  &lt;dbl&gt;\n1 0.371\n2 0.959\n3 0.633\n4 0.177\n5 0.803\n6 0.133\n\n\n\n\nSimulate subset only\n\nset.seed(500)\n\nspecify(a = ~ runif(6)) |&gt; \n  generate(3, .sim_id == 3)\n\nfull tibble\n--------------------------\n# A tibble: 1 × 3\n  .sim_id   rep sim             \n    &lt;int&gt; &lt;int&gt; &lt;list&gt;          \n1       3     3 &lt;tibble [6 × 1]&gt;\n\nsim[[1]]\n--------------------------\n# A tibble: 6 × 1\n      a\n  &lt;dbl&gt;\n1 0.371\n2 0.959\n3 0.633\n4 0.177\n5 0.803\n6 0.133\n\n\n\n\nBenchmarking\n\nset.seed(500)\n\nbench::mark(\n  all = specify(a = ~ runif(6)) |&gt; \n    generate(1000) |&gt; \n    dplyr::filter(.sim_id == 1000),\n  subset = specify(a = ~ runif(6)) |&gt; \n    generate(1000, .sim_id == 1000),\n  check = FALSE, min_iterations = 10L, relative = TRUE\n)\n\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n\n\n# A tibble: 2 × 6\n  expression   min median `itr/sec` mem_alloc `gc/sec`\n  &lt;bch:expr&gt; &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 all         56.5   56.0       1        1        1   \n2 subset       1      1        54.2      1.28     1.15\n\n\n\n\n\nOther features\n\n\n\n\n\n\nData munging\n\n\n\nAdd per_sim() |&gt; after generate() in your simulation pipeline and then any tidyverse function that will apply to every simulation dataset:\n\nspecify(\n  pre  = ~ rnorm(n, 0, sd), \n  post = ~ pre + rnorm(n, mean_diff, sd)\n) |&gt; \n  define(\n    n = c(100, 150, 200), \n    mean_diff = c(10, 20, 30), \n    sd = c(50, 100)\n  ) |&gt; \n  generate(1000, .progress = TRUE) |&gt; \n  ## Apply tidyverse functions to every simulation dataset\n  per_sim() |&gt; \n  ## Mutate to add a range restriction\n  dplyr::mutate(dplyr::across(dplyr::everything(), dplyr::case_when(\n    pre &gt;  100 ~ 100,\n    pre &lt; -100 ~ -100,\n    .default   ~ pre\n  ))) |&gt; \n  fit(t = ~ t.test(post, pre, paired = TRUE)) |&gt; \n  tidy_fits()\n\n\n\n\n\n\n\n\n\nError handling\n\n\n\n\nCan change error handling to keep going with simulation, stop simulation, or to skip warnings;\nDebug and recovery options to enter into simulation during error.\n\n\n\n\n\n\n\n\n\nBuilt-in parallelization\n\n\n\nJust add\n\nlibrary(future)\nplan(multisession, workers = 6) # or however many cores are reasonable to use\n\nand your simulation pipeline (actually the generate() function) will run in parallel.\n\n\n\n\nPros & Cons\n\n\n\n\n\n\n\n\nPros\n\n\n\n\ntidyverse friendly;\nbeginner friendly;\nReproducibility, error handling built in;\nGeneral-purpose, customizable and can handle arbitrary R code.\n\n\n\n\n\n\n\n\n\n\nCons\n\n\n\n\nLikely not as fast/optimized as some alternatives;\nNot as customizable/powerful as DeclareDesign;\nNot specifically set up for any particular application (no MC errors, plots, reports, specific models…)."
  },
  {
    "objectID": "simulator.html#getting-started",
    "href": "simulator.html#getting-started",
    "title": "Setting up simulations in R",
    "section": "Getting started",
    "text": "Getting started\nThe function “create”, with a directory that does not exist, will create the directory with 5 files :\n\neval_functions.R : contains metrics to be evaluated\nmain.R : main code to run\nmethod_functions.R : methods to run\nmodel_functions.R : define the models.\nwriteup.Rmd\n\n\nlibrary(simulator)\n\n\nAttaching package: 'simulator'\n\n\nThe following object is masked from 'package:simpr':\n\n    rename\n\ndir &lt;- \"./sims_simulator\"\nif (!file.exists(dir)) {\n  create(dir)\n}\n\n\nsetwd(dir)\n\nlist.files()\n\n[1] \"eval_functions.R\"   \"files\"              \"main.R\"            \n[4] \"method_functions.R\" \"model_functions.R\"  \"writeup_files\"     \n[7] \"writeup.html\"       \"writeup.Rmd\"       \n\n\n“On a typical project, one starts by defining a model in model_functions.R, one or two methods in method_functions.R, and a few metrics in eval_functions.R, and then one runs the code in main.R. After looking at some of the results, one might add an additional model or method or metric. One then returns to main.R, adds some additional lines specifying that the additional components should be run as well and looks at some more results.\nThe simplest way to look at results is by using the plot functions “plot_eval”, “plot_evals” and “plot_evals_by.” In situations where you wish to investigate results more deeply than just looking at aggregated plots, one can use the functions “model”, “draws”, “output”, and “evals” to get at all objects generated through the course of the simulation.”\nThe “create” function also create the template in the different files :\n\nwhat is in model_functions\n\nmake_my_model &lt;- function(n, prob) {\n  new_model(name = \"contaminated-normal\",\n            label = sprintf(\"Contaminated normal (n = %s, prob = %s)\", n, prob),\n            params = list(n = n, mu = 2, prob = prob),\n            simulate = function(n, mu, prob, nsim) {\n              # this function must return a list of length nsim\n              contam &lt;- runif(n * nsim) &lt; prob\n              x &lt;- matrix(rep(NA, n * nsim), n, nsim)\n              x[contam] &lt;- rexp(sum(contam))\n              x[!contam] &lt;- rnorm(sum(!contam))\n              x &lt;- mu + x # true mean is mu\n              return(split(x, col(x))) # make each col its own list element\n            })\n}\n\nDefine a model from its different components with “new_model” :\n\nname\nlabel : what will be printed in the tables later probably ?\nparam : a list of different parameters for the model\nsimulate : a function of the parameters, that returns nsim simulations.\n\n\n\nwhat is in method_functions\n\nmy_method &lt;- new_method(\"my-method\", \"My Method\",\n                        method = function(model, draw) {\n                          list(fit = median(draw))\n                        })\n\ntheir_method &lt;- new_method(\"their-method\", \"Their Method\",\n                           method = function(model, draw) {\n                             list(fit = mean(draw))\n                           })\n\nDefine methods to be used on the model. The function “new_method” has for arguments a name (for R), a pretty name, and the “method” named arg for the computation we want.\n\n\nwhat is in eval_functions\n\nhis_loss &lt;- new_metric(\"hisloss\", \"His loss function\",\n                        metric = function(model, out) {\n                          return((model$mu - out$fit)^2)\n})\n\nher_loss &lt;- new_metric(\"herloss\", \"Her loss function\",\n                        metric = function(model, out) {\n                          return(abs(model$mu - out$fit))\n                        })\n\nMetric objects : shows how to compare model object and output of the method (method used on sim) object.\n\n\nwhat is in main\n\nsetwd(dir)\n\n# This is the main simulator file\n\n\nlibrary(simulator) # this file was created under simulator version 0.2.5\n\nsource(\"model_functions.R\")\nsource(\"method_functions.R\")\nsource(\"eval_functions.R\")\n\n## @knitr init\n\nname_of_simulation &lt;- \"normal-mean-estimation-with-contamination\"\n\n## @knitr main\n\nsim &lt;- new_simulation(name = name_of_simulation,\n                      label = \"Mean estimation under contaminated normal\") %&gt;%\n  generate_model(make_my_model, seed = 123,\n                 n = 50,\n                 prob = as.list(seq(0, 1, length = 6)),\n                 vary_along = \"prob\") %&gt;%\n  simulate_from_model(nsim = 10) %&gt;%\n  run_method(list(my_method, their_method)) %&gt;%\n  evaluate(list(his_loss, her_loss))\n\n..Created model and saved in contaminated-normal/n_50/prob_0/model.Rdata\n..Created model and saved in contaminated-normal/n_50/prob_0.2/model.Rdata\n..Created model and saved in contaminated-normal/n_50/prob_0.4/model.Rdata\n..Created model and saved in contaminated-normal/n_50/prob_0.6/model.Rdata\n..Created model and saved in contaminated-normal/n_50/prob_0.8/model.Rdata\n..Created model and saved in contaminated-normal/n_50/prob_1/model.Rdata\n..Simulated 10 draws in 0 sec and saved in contaminated-normal/n_50/prob_0/r1.Rdata\n..Simulated 10 draws in 0 sec and saved in contaminated-normal/n_50/prob_0.2/r1.Rdata\n..Simulated 10 draws in 0 sec and saved in contaminated-normal/n_50/prob_0.4/r1.Rdata\n..Simulated 10 draws in 0 sec and saved in contaminated-normal/n_50/prob_0.6/r1.Rdata\n..Simulated 10 draws in 0 sec and saved in contaminated-normal/n_50/prob_0.8/r1.Rdata\n..Simulated 10 draws in 0 sec and saved in contaminated-normal/n_50/prob_1/r1.Rdata\n..Performed My Method in 0 seconds (on average over 10 sims)\n..Performed Their Method in 0 seconds (on average over 10 sims)\n..Performed My Method in 0 seconds (on average over 10 sims)\n..Performed Their Method in 0 seconds (on average over 10 sims)\n..Performed My Method in 0 seconds (on average over 10 sims)\n..Performed Their Method in 0 seconds (on average over 10 sims)\n..Performed My Method in 0 seconds (on average over 10 sims)\n..Performed Their Method in 0 seconds (on average over 10 sims)\n..Performed My Method in 0 seconds (on average over 10 sims)\n..Performed Their Method in 0 seconds (on average over 10 sims)\n..Performed My Method in 0 seconds (on average over 10 sims)\n..Performed Their Method in 0 seconds (on average over 10 sims)\n..Evaluated My Method in terms of \nHis loss function, Her loss function, Computing time (sec)\n..Evaluated Their Method in terms of \nHis loss function, Her loss function, Computing time (sec)\n..Evaluated My Method in terms of \nHis loss function, Her loss function, Computing time (sec)\n..Evaluated Their Method in terms of \nHis loss function, Her loss function, Computing time (sec)\n..Evaluated My Method in terms of \nHis loss function, Her loss function, Computing time (sec)\n..Evaluated Their Method in terms of \nHis loss function, Her loss function, Computing time (sec)\n..Evaluated My Method in terms of \nHis loss function, Her loss function, Computing time (sec)\n..Evaluated Their Method in terms of \nHis loss function, Her loss function, Computing time (sec)\n..Evaluated My Method in terms of \nHis loss function, Her loss function, Computing time (sec)\n..Evaluated Their Method in terms of \nHis loss function, Her loss function, Computing time (sec)\n..Evaluated My Method in terms of \nHis loss function, Her loss function, Computing time (sec)\n..Evaluated Their Method in terms of \nHis loss function, Her loss function, Computing time (sec)\n\n## @knitr plots\n\nplot_eval_by(sim, \"hisloss\", varying = \"prob\")\n\n\n\n\n\n\n\n## @knitr tables\n\ntabulate_eval(sim, \"herloss\", output_type = \"markdown\",\n              format_args = list(digits = 1))\n\n&lt;!-- generated by simulator on Tue Aug 20 14:21:08 2024. --&gt;\n\n\n\nA comparison of Mean Her loss function (averaged over 10 replicates).\n\n\n\nMy Method\nTheir Method\n\n\n\n\nContaminated normal (n = 50, prob = 0)\n0.11 (0.02)\n0.07 (0.02)\n\n\nContaminated normal (n = 50, prob = 0.2)\n0.25 (0.05)\n0.25 (0.06)\n\n\nContaminated normal (n = 50, prob = 0.4)\n0.38 (0.06)\n0.37 (0.06)\n\n\nContaminated normal (n = 50, prob = 0.6)\n0.52 (0.04)\n0.63 (0.06)\n\n\nContaminated normal (n = 50, prob = 0.8)\n0.63 (0.04)\n0.86 (0.03)\n\n\nContaminated normal (n = 50, prob = 1)\n0.70 (0.05)\n1.03 (0.05)\n\n\n\n\n\nmain calls the different files.\n? Can plot_eval_by be used for different metrics at once ? ? Can tabulate_eval be used for different metrics at once ?"
  },
  {
    "objectID": "simulator.html#important-functions",
    "href": "simulator.html#important-functions",
    "title": "Setting up simulations in R",
    "section": "Important functions :",
    "text": "Important functions :\n\nnew_model()\nnew_method()\nnew_metric()\nnew_simulation\ngenerate_model\nsimulate_from_model\nrun_method\nevaluate\nplot_eval, plot_eval_by, tabulate_eval."
  },
  {
    "objectID": "simulator.html#final-notes",
    "href": "simulator.html#final-notes",
    "title": "Setting up simulations in R",
    "section": "Final notes :",
    "text": "Final notes :\nThis is not really a package that codes a method, but instead it proposes an architecture to store your codes, output simulations, results, etc.\nPROs :\n\nany model possible, if you can write it !\npossible to iterate over parameter with pretty pipes\nparallel possible, because you choose what you use\nstores all results in the storage with increasing depth:\nfiles\n\nname_of_model\n\nname_of_first_param_value\n\nname_of2nd_param_value … model.Rdata out : stores all sims\n\nr?.Rdata\n\n\n\n\n\nCONs :\n\nNot an usual way to code in R, and not easy to explain. create the directory with the “create” function. Then, add the different functions, methods, models… in the corresponding files.\nMixes the code of the package/template with your own code.\nstores all results in this neat way BUT if too many parameters, may exceed the depth allowed."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "",
    "text": "L’atelier Finist’R 2024 – ou bootcamp R du groupe State Of The R s’est déroulé à la station biologique de Roscoff du 19 au 23 août 2024.\nStateoftheR est un réseau du département MathNum INRAE.\n\n\nIl s’agit de la huitième édition de l’atelier Finist’R. Cet atelier réunit annuellement un groupe de chercheurs, ingénieurs, doctorants, tous utilisateurs avancés de R et développeurs de paquets pour explorer les dernières fonctionnalités du logiciel et les nouvelles pratiques de développement. A l’issue de l’atelier le collectif produit une synthèse de cette veille logiciel de manière à progresser collectivement dans l’utilisation du logiciel mais surtout dans la production d’outils statistiques à destination de la communauté.\nLe résultat de cette semaine est disponible sur cette page"
  },
  {
    "objectID": "index.html#où-quand",
    "href": "index.html#où-quand",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "",
    "text": "L’atelier Finist’R 2024 – ou bootcamp R du groupe State Of The R s’est déroulé à la station biologique de Roscoff du 19 au 23 août 2024.\nStateoftheR est un réseau du département MathNum INRAE.\n\n\nIl s’agit de la huitième édition de l’atelier Finist’R. Cet atelier réunit annuellement un groupe de chercheurs, ingénieurs, doctorants, tous utilisateurs avancés de R et développeurs de paquets pour explorer les dernières fonctionnalités du logiciel et les nouvelles pratiques de développement. A l’issue de l’atelier le collectif produit une synthèse de cette veille logiciel de manière à progresser collectivement dans l’utilisation du logiciel mais surtout dans la production d’outils statistiques à destination de la communauté.\nLe résultat de cette semaine est disponible sur cette page"
  },
  {
    "objectID": "index.html#participants",
    "href": "index.html#participants",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "Participants",
    "text": "Participants\nBaptiste Alglave, Emré Anakok, Julie Aubert, Pierre Barbillon, Julien Chiquet, Lucia Clarotto, Caroline Cognot, Annaïg De Walsche, Sophie Donnet, Marie-Pierre Etienne, Armand Favrot, Hugo Gangloff, Pierre Gloaguen, Adeline Leclercq Samson, Tristan Mary-Huard, Cédric Midoux, Pierre Neuvial, Aymeric Stamm, Florian Teste, François Victor, Emily Walker."
  },
  {
    "objectID": "index.html#soutien",
    "href": "index.html#soutien",
    "title": "FinistR : bootcamp R à Roscoff",
    "section": "Soutien",
    "text": "Soutien"
  },
  {
    "objectID": "sims_simulator/writeup.html",
    "href": "sims_simulator/writeup.html",
    "title": "My Simulation",
    "section": "",
    "text": "This is a knitr report generated by the simulator to describe your simulation. Knitting this file will rerun the simulation if any of the code files have been modified since the simulation object was last created."
  },
  {
    "objectID": "sims_simulator/writeup.html#models",
    "href": "sims_simulator/writeup.html#models",
    "title": "My Simulation",
    "section": "Models",
    "text": "Models\n\nmake_my_model &lt;- function(n, prob) {\n  new_model(name = \"contaminated-normal\",\n            label = sprintf(\"Contaminated normal (n = %s, prob = %s)\", n, prob),\n            params = list(n = n, mu = 2, prob = prob),\n            simulate = function(n, mu, prob, nsim) {\n              # this function must return a list of length nsim\n              contam &lt;- runif(n * nsim) &lt; prob\n              x &lt;- matrix(rep(NA, n * nsim), n, nsim)\n              x[contam] &lt;- rexp(sum(contam))\n              x[!contam] &lt;- rnorm(sum(!contam))\n              x &lt;- mu + x # true mean is mu\n              return(split(x, col(x))) # make each col its own list element\n            })\n}"
  },
  {
    "objectID": "sims_simulator/writeup.html#methods",
    "href": "sims_simulator/writeup.html#methods",
    "title": "My Simulation",
    "section": "Methods",
    "text": "Methods\n\nmy_method &lt;- new_method(\"my-method\", \"My Method\",\n                        method = function(model, draw) {\n                          list(fit = median(draw))\n                        })\n\ntheir_method &lt;- new_method(\"their-method\", \"Their Method\",\n                           method = function(model, draw) {\n                             list(fit = mean(draw))\n                           })"
  },
  {
    "objectID": "sims_simulator/writeup.html#metrics",
    "href": "sims_simulator/writeup.html#metrics",
    "title": "My Simulation",
    "section": "Metrics",
    "text": "Metrics\n\nhis_loss &lt;- new_metric(\"hisloss\", \"His loss function\",\n                        metric = function(model, out) {\n                          return((model$mu - out$fit)^2)\n})\n\nher_loss &lt;- new_metric(\"herloss\", \"Her loss function\",\n                        metric = function(model, out) {\n                          return(abs(model$mu - out$fit))\n                        })"
  },
  {
    "objectID": "instructions.html",
    "href": "instructions.html",
    "title": "Instructions pour le dépot sur le site web",
    "section": "",
    "text": "Protocole https :\ngit clone https://github.com/StateOfTheR/finistR2024.git\nAvec clés SSH : git clone git@github.com:git@github.com:StateOfTheR/finistR2024.git\n\n\n(Lien vers une doc complète)[https://docs.github.com/fr/get-started/getting-started-with-git/managing-remote-repositories]."
  },
  {
    "objectID": "instructions.html#cloner-le-dépôt-git-du-bootcamp",
    "href": "instructions.html#cloner-le-dépôt-git-du-bootcamp",
    "title": "Instructions pour le dépot sur le site web",
    "section": "",
    "text": "Protocole https :\ngit clone https://github.com/StateOfTheR/finistR2024.git\nAvec clés SSH : git clone git@github.com:git@github.com:StateOfTheR/finistR2024.git\n\n\n(Lien vers une doc complète)[https://docs.github.com/fr/get-started/getting-started-with-git/managing-remote-repositories]."
  },
  {
    "objectID": "instructions.html#processus-de-mise-en-commun-des-ateliers",
    "href": "instructions.html#processus-de-mise-en-commun-des-ateliers",
    "title": "Instructions pour le dépot sur le site web",
    "section": "Processus de mise en commun des ateliers",
    "text": "Processus de mise en commun des ateliers\n\nCréer une branche propre à l’atelier nommée explicitement mon_nom_parlant et basculer dessus\n\ngit checkout -b mon_nom_parlant\n\nCréer un fichier Rmarkdown de restitution de votre atelier fichier.Rmd dans votre branche\n\ngit add fichier.Rmd\ngit commit -m \"restitution atelier\"\n\nPousser vos modifications sur le serveur distant\n\ngit  push --set-upstream origin mon_nom_parlant ou\ngit  push\n\nFaire une pull request (PR) sur github\nindiquer dans le message de la PR la liste des packages ou autres besoins\nQuand la PR passe les tests, demander le merge.\ncorriger les erreurs éventuelles dans la compilation du Rmarkdown\nles admins peuvent avoir à mettre à jour l’image docker"
  },
  {
    "objectID": "instructions.html#détails-du-fonctionnement",
    "href": "instructions.html#détails-du-fonctionnement",
    "title": "Instructions pour le dépot sur le site web",
    "section": "Détails du fonctionnement",
    "text": "Détails du fonctionnement\n\nLe docker\n(Lien vers la fiche pense-bête)[https://www.docker.com/sites/default/files/d8/2019-09/docker-cheat-sheet.pdf]\nPour créer des images Docker en local sur sa machine, voici une liste de commandes utiles\n\nPour construire une image docker, il faut créer un fichier Dockerfile qui contient la recette du Docker. Pour ce site le ficher Dockerfile a la forme suivante\n\n\n\n\nFROM rocker/geospatial:4.4\nRUN export DEBIAN_FRONTEND=noninteractive; apt-get -y update \\\n && apt-get install -y pandoc \\\n    pandoc-citeproc\nRUN R -e \"install.packages('remotes')\"\nRUN R -e \"install.packages('microbenchmark')\"\nRUN R -e \"install.packages('purrr')\" # map function\nENV R_CRAN_WEB=\"https://cran.rstudio.com/\"\nRUN R -e \"install.packages('cowplot')\" # GET function\nRUN R -e \"install.packages('torch')\"\nRUN R -e \"torch::install_torch(type = 'cpu')\"\nRUN R -e \"install.packages('PLNmodels')\"\nRUN R -e \"install.packages('torchvision')\"\n\nRUN apt-get update \\\n && apt-get install -y --no-install-recommends \\\n  mercurial gdal-bin libgdal-dev gsl-bin libgsl-dev \\\n  libc6-i386\n\nRUN R -e \"install.packages('reticulate')\"\nRUN R -e \"install.packages(c('inlabru', 'lme4', 'ggpolypath', 'RColorBrewer', 'geoR'))\"\nRUN R -e \"install.packages(c('poissonreg'))\"\nRUN apt-get install -y --no-install-recommends unzip python3-pip dvipng pandoc wget git make python3-venv && \\\n    pip3 install jupyter jupyter-cache flatlatex matplotlib && \\\n    apt-get --purge -y remove texlive.\\*-doc$ && \\\n    apt-get clean\n\n\npuis demander la construction de l’image à l’aide de la commande\n\n docker build -t nom_depot_dockerhub/nom_du_repo:version  . ## avec un nom\n\net enfin pousser sur Dockerhub\n\n docker push nom_depot_dockerhub/nom_du_repo:version\n\n\n\nLes actions\nDans les action de Github, on peut spécifier un container docker à utiliser, c’est ce que fait la ligne container du fichier d’action suivant, utiliser pour créer ce site web\n\n\nname: website\non:\n  push:\n    branches:\n      - main\n\njobs:\n  build:\n    name: Build website with rmarkdown\n    runs-on: ubuntu-latest\n    container: stateofther/r-finistr2024:0.1\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n      - name: Additional Packages\n        run: Rscript -e \"install.packages(c('tictoc'))\"\n      - name: Generate slides\n        run: \"quarto render\"\n      - name: GitHub Pages action\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./_site"
  },
  {
    "objectID": "Readme.html",
    "href": "Readme.html",
    "title": "Ateliers Finist’R 2024",
    "section": "",
    "text": "Ateliers Finist’R 2024\n\n\n\nwebsite\n\n\nL’atelier Finist’R 2024 – ou bootcamp R s’est déroulé à la station biologique de Roscoff du 19 au 23 août 2024.\nIl s’agit de la huitième édition de l’atelier Finist’R. Cet atelier réunit annuellement un groupe de chercheurs, ingénieurs, doctorants, tous utilisateurs avancés de R et dévelopeurs de paquets pour explorer les dernières fonctionalités du logiciel et les nouvelles pratiques de développement. A l’issu de l’atelier le collectif produit une synthèse de cette veille logiciel de manière à progresser collectivement dans l’utilisation du logiciel mais surtout dans la production d’outils statistiques à destination de la communauté.\nLa restitution se fait sous forme de site web. Le site de l’édition 2024 sera disponible ici"
  }
]